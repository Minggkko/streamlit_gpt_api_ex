########### ì„¤ì¹˜ ###########
# pip install openai streamlit python-dotenv
###########################

import os
import time
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

# ====== í™˜ê²½ ì„¤ì • ======
load_dotenv(override=True)
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
client = OpenAI(api_key=api_key)

# ====== UI ======
st.title("ğŸŒ ë‹¤êµ­ì–´ TTS + ìë™ ì„±ìš° ì¶”ì²œ (ë…ë¦½ ì‹¤í–‰)")

st.image("https://wikidocs.net/images/page/215361/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%84%B1%EC%9A%B0.jpg", width=200)

# ì–¸ì–´ ì„ íƒ
languages = {
    "í•œêµ­ì–´": "Korean",
    "ì˜ì–´": "English",
    "ì¼ë³¸ì–´": "Japanese",
    "ì¤‘êµ­ì–´(ê°„ì²´)": "Chinese (Simplified)",
    "ìŠ¤í˜ì¸ì–´": "Spanish",
    "í”„ë‘ìŠ¤ì–´": "French",
}
selected_lang = st.selectbox("ğŸ§ ìƒì„±í•  ìŒì„± ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(languages.keys()))

# í…ìŠ¤íŠ¸ ì…ë ¥
default_text = "í¬ê¸°í•˜ì§€ ì•ŠëŠ” ê°„ì ˆí•œ ê¿ˆì€ ê¼­ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤."
user_prompt = st.text_area("ğŸ¤ ì½ì„ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:", value=default_text, height=160)

# ====== ì„±ìš° ì¶”ì²œ ======
def recommend_voice(prompt):
    """ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜ ì¶”ì²œ"""
    if any(word in prompt for word in ["ê¿ˆ", "í¬ë§", "ìš©ê¸°", "í–‰ë³µ", "ì‘ì›", "í™”ì´íŒ…"]):
        return "nova"
    if any(word in prompt for word in ["ì–´ë‘ ", "ìœ„ê¸°", "ì „ìŸ", "ê³µí¬", "ìŠ¬í””"]):
        return "onyx"
    if any(word in prompt for word in ["ì‚¬ë‘", "ì¶”ì–µ", "ê°ì„±", "ê·¸ë¦¬ì›€"]):
        return "fable"
    if any(word in prompt for word in ["ê¸°ìˆ ", "ë¡œë´‡", "ë¯¸ë˜", "ë°ì´í„°"]):
        return "echo"
    return "alloy"

recommended_voice = recommend_voice(user_prompt)
st.info(f"ğŸ™ï¸ ì¶”ì²œ ì„±ìš°: **{recommended_voice}**")

# ì„±ìš° ì„ íƒ ë°•ìŠ¤ (ì¶”ì²œ ì„±ìš° ê¸°ë³¸ê°’)
voices_list = ['alloy', 'ash', 'coral', 'echo', 'fable', 'onyx', 'nova', 'sage', 'shimmer']
default_index = voices_list.index(recommended_voice) if recommended_voice in voices_list else 0
voice = st.selectbox("ğŸ¤ ì„±ìš°ë¥¼ ì„ íƒí•˜ì„¸ìš”:", voices_list, index=default_index)

# ====== OpenAIë¡œ ë²ˆì—­ ======
def translate_text(text, target_language_name):
    """OpenAI chat completionì„ ì´ìš©í•´ ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­"""
    messages = [
        {"role": "system", "content": f"You are a translator. Translate the user's sentence into {target_language_name}."},
        {"role": "user", "content": text}
    ]
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0,
        max_tokens=1000
    )
    return resp.choices[0].message.content.strip()

# ====== ë²„íŠ¼ ======
if st.button("ğŸ”Š Generate Audio"):

    with st.spinner("ë²ˆì—­ ì¤‘..."):
        try:
            translated_text = translate_text(user_prompt, languages[selected_lang])
        except Exception as e:
            st.error(f"ë²ˆì—­ ì‹¤íŒ¨: {e}")
            translated_text = None

    if translated_text:
        st.write("ğŸ’¬ ë²ˆì—­ëœ í…ìŠ¤íŠ¸:")
        st.success(translated_text)

        with st.spinner("ìŒì„± ìƒì„± ì¤‘..."):
            try:
                audio_response = client.audio.speech.create(
                    model="tts-1",
                    voice=voice,
                    input=translated_text
                )
            except Exception as e:
                st.error(f"ìŒì„± ìƒì„± ì‹¤íŒ¨: {e}")
                audio_response = None

        if audio_response:
            os.makedirs("output_audio", exist_ok=True)
            path = f"output_audio/audio_{int(time.time())}.mp3"
            with open(path, "wb") as f:
                f.write(audio_response.content)

            st.audio(path, format="audio/mp3")
            st.download_button("â¬‡ï¸ ë‹¤ìš´ë¡œë“œ", data=open(path, "rb"), file_name="translated_audio.mp3")
            st.success("âœ… ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
